# Algorithm

[TOC]



## 1. 矩阵分解

### 1.1 隐语义模型(LFM)

Latent Factor Model.通过隐含特征联系用户兴趣以及物品,对于某一个用户首先找到其兴趣分类,然后从兴趣分类中选择他可能喜欢的物品.通过将用户的评分矩阵映射到一个低维的隐语义空间中,挖掘用户的隐因子以及item的隐因子.

隐因子模型即矩阵分解模型:

**SVD:**
$$
R = u * \sum * V^T \\
m*n \; m*r \; r*r \; r*n
$$
传统的SVG要求矩阵稠密，需要对于评分矩阵进行补全，对于高维稀疏的评分矩阵难以应用。

#### FunkSVD

将一个`mxn`的矩阵分解为两个矩阵`P`, `Q`,分别表示用户以及item的隐因子矩阵。

- $p_{ir}$: 表示用户i与隐因子r的相关程度
- $Q_{r, j}$: 表示物品j与隐因子r的相关程度

构建一个损失函数，利用机器学习的方法进行训练:
$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1} ^{n} (p_i - r_i)^2}
$$
对于得到的两个低维向量，定义损失函数:
$$
\hat{r} = pq \\
loss(p, q) = \sum _{(u, i) \in Train} (r_{ui} \; - \sum_{f = 1} ^{F} p_{uf} \; q_{fi}) ^2
$$

#### Regularized MF

在基本的矩阵分解的损失函数上加入了正则化，降低过拟合的风险：
$$
loss(p, q) = \sum _{(u, i) \in Train} (r_{ui} \; - \sum_{f = 1} ^{F} p_{uf} \; q_{fi}) ^2 + 
\lambda(||p_u||^2 + ||q_i||^2)
$$
超参数；

- 隐因子的隐含维度F
- 梯度下降的学习率
- 正则化的惩罚因子 $\lambda$
- 正负样本的比例r

#### BiasSVD

BiasSVD 假设评分系统包括三部分的偏置因素：

- 一些与用户物品无关的评分因素
- 用户偏置项：用户有一些和物品无关的评分因素
- 物品偏置项： 物品有一些和用户无关的偏置因素

最终一个用户的评分由4部分组成，原有的矩阵分解结果与系统平均分、用户偏置项、物品偏置项的和
$$
\hat{r_{ui}} = p_u q_i + \mu_u + b_u + b_i
$$
损失函数:
$$
loss(p, q) = \sum _{(u, i) \in Train} (r_{ui} -\mu_u - b_u - b_i\; - \sum_{f = 1} ^{F} p_{uf} \; q_{fi}) ^2 + 
\lambda(||p_u||^2 + ||q_i||^2)
$$

#### SVD++

SVD++ 在BiasSVD方法上进行了改进，考虑到了用户的隐式反馈。充分利用了评分矩阵中的缺失值:

考虑到了邻域的影响:

ItemCF:

+ $N(u)$: 用户u的物品偏好集合
+ S(j, K): 与物品j最相近的K个物品的而集合
+ $w_{ij}$: 物品i，j的相似度
+ $r_{ui}$: 用户u对于物品i的评分

那么基于物品的方法中，用户的评分:
$$
p_{uj} = \sum_{i \in N(u) \cap S(j, K)}w_{ij}r_{ui}
$$
为了求出$w_{ij}$,可以使用一下损失函数:
$$
loss(w) = \sum_{(u,i) \in Train} (r_{ui} - \sum_{j \in N(u)}w_{ij}r_{uj})^2 + \lambda w_{ij}^2 
$$
由于w是一个稠密矩阵，存储是需要较大的空间，所以需要对于w也进行分解：
$$
\hat{r_{ui}} = \frac{1}{\sqrt{|N(u)|}}\sum_{j \in N(u)}w_{ij} \\
 = \frac{1}{\sqrt{|N(u)|}}\sum_{j \in N(u)} x_i^Ty_i = \frac{1}{\sqrt{|N(u)|}} x_i^T \sum_{j \in N(u)} y_i
$$
最终的SVD++：
$$
\hat{r_{ui}} =  \mu_u + b_u + b_i + p_u q_i + \frac{1}{\sqrt{|N(u)|}} x_i^T \sum_{j \in N(u)} y_i \\
\hat{r_{ui}} =  \mu_u + b_u + b_i + p_u( q_i + \frac{1}{\sqrt{|N(u)|}}\sum_{j \in N(u)} y_i)
$$
**用户兴趣：显式兴趣 + 偏见 + 隐式反馈**

## 2. 因子分解机（FM）

Factorization Machines。主要用于解决数据高维稀疏的情况下，特征组合问题。

+ 利用FM发现item不同属性间的关联性
+ 减少人工参与特征组合工作

优点:

+ 可以在非常稀疏的数据中进行合理的参数估计
+ 线性时间复杂度
+ FM是一个通用模型

### 工具

+ LibFM

## 3. 图模型的推荐

### 3.1 SimRank

基于图的拓扑结构衡量任意两个对象间的相似程度，完全基于结构信息。

**如果两个对象被其他相似的对象引用（具有相似的入邻边结构），那么这两个对象也相似。**

如果两个用户相似，那么与这两个用户关联的物品也相似。

某一个子集内两点间的相似度可以使用另一个子集内的结点的相似度表示:
$$
s(a, b) = \frac{C}{|I(a)| \;|I(b)|} \sum _{i = 1} ^{|I(a)|} \sum_{j = 1} ^{|I(b)|} s(I_i(a), I_j(b)) \;\;\; a != b; I(a) != 0; I(b) != 0
$$

### 3,2 PearsonRank

基于随机游走的PersonRank算法。

+ 从用户u对应的结点$V_u$开始在用户物品二部图上进行随机游走
+ 到达任何一个节点，首先按照一定的概率a继续游走，或者以1-a的概率从$V_u$重新游走
+ 如果继续游走，就从当前结点指向的结点按照均匀分布随机选择一个结点
+ 这样经过很多次游走之后，每一个节点被访问的概率会逐渐收敛
+ 最终物品列表的权重就是被访问到的概率

### 3.3 时间段图模型

时间段图是一个二分图，$G(U, S_U, I, S_I, E, \omega, \sigma)$

+ 用户
+ 用户时间段结点集合
+ 物品
+ 物品时间段结点集合
+ 边的权重
+ 顶点的权重

**路径融合：**

+ 首先提取初连个顶点间长度小于一个阈值的所有路径

+ 然后根据每条路径p经过的顶点，为每条路径赋予一定的权重
  $$
  A(P) = \sigma(v_n) \prod_{i = 1} ^{n-1} \frac{\sigma(v_i) * w(v_i, v_{i+1})}{|out(v_i)|^a}
  $$

+ 最后将两个顶点间所有路径的权重之和作为相关度

### 3.4 地理位置感知推荐

$$
RS(u, i) = P(u, i) - Travel(u, i)
$$

Travel项表示物品i的位置对于用户i的代价。为了避免计算所有的物品的位置代价，可以确定一个候选集，里面的所有item的距离与用户评分过的Item距离小于某一个阈值.

## 4. Bandit 算法

### 4.1 $\epsilon-Greedy$

+ 选择一个超参数$\epsilon$ ,(0,1)间较小的数
+ 每次以该概率去勘探Exporation, 以1-e的概率去开发Exploitation
+ 不断循环下去

好处：

+ 可以应对变化，如果item的回报发生变化，可以及时调整策略，避免位于次优状态
+ 可以控制对于EE的偏好程度

变体：

+ $\epsilon$-First:

  首先以较少的次数进行随机尝试，确定哪些Item可以获得较高的回报；接下来较多的次数选择前面确定回报较高的item

+ $\epsilon$-descreasing

  使得进行勘探的概率随着时间的逐渐降低，增加开发的比重。

### 4.2 Thompson Sampling

基于贝叶斯的思想，全部使用概率分布表达不确定性，Thompson采样使用到了beta分布，是二项分布的共轭分布。

贝叶斯学派不假定概率p有一个固定的值，但是可能服从某一种分布。

+ 假设每一个老虎机都有一个收益的概率p
+ 该概率服从beta分布 beta(wins, lose)
+ 每次试验后，如果得到收益，则wins+1，否则lose+1
+ 不断试验，估计一个置信度较高的p的分布

**每次选择臂的方式，每一个臂对应一个beta分布的随机数，选择所有随机数最大的臂**

**pymc**

### 4.3 UCB 算法

置信区间上界。完全不使用随机性，除了考虑收益外还需要考虑该收益的置信度。
$$
UCB = \hat{x_j} + \sqrt{\frac{1lnn}{n_j}} \\
\hat{x_j}: 观测到第j个臂的平均回报 \\
n_j: 按压到第j个臂的次数 \\
n： 按压的总次数
$$
**该公式反映了：均值越大、标准差越小，被选中的概率越大；同时那些被选中较少的臂也会得到训练机会**

+ 初始化：先对每一个臂试一遍
+ 计算每一个臂的分数，选择分数最大的
+ 观察结果，更新nj, n



## 5. 深度学习模块

### 5.1 深度网络用于RecSys的方式

1. 利用深度模型进行表示学习
2. 利用深度模型进行匹配函数的学习

### 5.2 DSSM

Deep Semantic Similarity Model。通过深度网络将不同的高维稀疏特征映射到一个低维空间，然后利用余弦计算相似度。通常使用MLP，经过多层非线性映射，得到用户以及item的较低纬度的向量表示，再计算相似度。

同时具有多视图的模型，将用户的输入数据分为z不同的域，从而得到z个不同的输出。

### 5.3 Auto Encoder

一种无监督方法，可以得到高维向量的一个低维表示。目标是使用MLP得到的模型，使得输出尽可能接近于输入。

对于原有向量x的非线性映射得到y，可以经过分线性映射得到x。这样第一组参数就很好的学习了X的特征。

+ User-based

  + 输入： 用户作用过的item表示user
  + 得到的隐含层向量可以表示user
  + 隐含层结点到输出层的结点的权重表示item
  + 计算user， item的内积作为相似度度量

  **item-based性能好过userbased， 数据过于稀疏时效果不好**

### 5.4 ACF

Attention Collaborative Filtering.协同过滤中引入attention机制，用以解决多媒体推荐中商品以及元素层级的隐式反馈带来的挑战。

+ Item 表示
  + 用CNN提取图像特征
  + 不同的部分对于item的Embedding的贡献不同，表示用户对于不同特征的偏好程度
  + 由Item的不同部分特征组合出不同item的表示
+ user 表示
  + 表示用户对于不同item的偏好



### 5.5 NCF 模型

+ MLP 使用多层感知机代替匹配函数
+ GMF user， item的Embedding通过逐元素的乘积进行结合， 然后作为MLP的输入
+ NeuMF 使用user, item Embedding的内积用来捕捉低维的关联；使用MLP捕捉高维关联

1. 对于user， item分别设置两个独立的Embedding层，MF_user, MF_item, MLP_user, MLP_item
2. MF_USER, MF_Item内积得到GMF的输出
3. MLP_user, MLP_item连接后经过MLP得到MLP的输出
4. 将两个输出连接起来，再放入一个FC中得到最终的评分